#!/usr/bin/env python
"""
This is the main program to run Mindboggle.

For help in using Mindboggle ::

    - Online `documentation <http://mindboggle.info/documentation.html>`_
    - README file
    - Help on the command line::

        $ mindboggle --help

This file uses Nipype (http://www.nipy.org/nipype/) to create a workflow
environment that enables Mindboggle to run in a flexible, modular manner
while storing provenance information.

Authors:
    - Arno Klein, 2010-2016  (arno@mindboggle.info)  http://binarybottle.com
    - Satrajit S. Ghosh, 2013  (satra@mit.edu)  http://www.mit.edu/~satra/
    - Each file lists Mindboggle team members who contributed to its content.

Copyright 2016,  Mindboggle team (http://mindboggle.info), Apache v2.0 License

"""

import os
import argparse
# ----------------------------------------------------------------------------
# Nipype libraries
# ----------------------------------------------------------------------------
from nipype import config, logging
from nipype.interfaces.ants import ApplyTransforms
from nipype.interfaces.io import DataGrabber, DataSink
from nipype.interfaces.utility import Function as Fn
from nipype.interfaces.utility import IdentityInterface
from nipype.pipeline.engine import Workflow, Node
# ----------------------------------------------------------------------------
# Mindboggle libraries
# ----------------------------------------------------------------------------
from mindboggle.features.folds import extract_folds
from mindboggle.features.fundi import extract_fundi, segment_fundi
from mindboggle.features.sulci import extract_sulci
from mindboggle.guts.mesh import rescale_by_neighborhood
from mindboggle.guts.paths import smooth_skeleton
from mindboggle.guts.relabel import relabel_surface, relabel_volume, \
    keep_volume_labels, remove_volume_labels, overwrite_volume_labels
from mindboggle.guts.segment import combine_2labels_in_2volumes
from mindboggle.guts.utilities import list_strings
from mindboggle.mio.convert_volumes import convert2nii
from mindboggle.mio.fetch_data import hashes_url, fetch_check_data, \
    fetch_ants_data
from mindboggle.mio.labels import DKTprotocol
from mindboggle.mio.tables import write_shape_stats, write_vertex_measures
from mindboggle.mio.vtks import read_vtk, apply_affine_transforms, \
    freesurfer_surface_to_vtk, freesurfer_curvature_to_vtk, \
    freesurfer_annot_to_vtk
from mindboggle.shapes.laplace_beltrami import spectrum_per_label
from mindboggle.shapes.likelihood import compute_likelihood
from mindboggle.shapes.surface_shapes import area, curvature, travel_depth, \
    geodesic_depth
from mindboggle.shapes.volume_shapes import thickinthehead, \
    volume_per_brain_region
from mindboggle.shapes.zernike.zernike import zernike_moments_per_label
from mindboggle.thirdparty.ants import PropagateLabelsThroughMask

# ============================================================================
#
#   Command-line arguments
#
# ============================================================================
parser = argparse.ArgumentParser(description="""
                    The Mindboggle software automates shape analysis of
                    anatomical labels and features extracted from human brain
                    MR image data (http://mindboggle.info).""",
                     formatter_class = lambda prog:
                     argparse.HelpFormatter(prog, max_help_position=40))

shp_args = parser.add_argument_group('experimental settings')
out_args = parser.add_argument_group('modify outputs')
adv_args = parser.add_argument_group('advanced input settings')

# "positional arguments":
parser.add_argument("DATA", help=("path to directory of an individual's "
                                  "brain image data, usually generated by "
                                  "the FreeSurfer software package"))
# "optional arguments":
parser.add_argument("--ants",
                    help=("path to brain segmentation file (ex: "
                          "/data/arno/antsBrainSegmentation.nii.gz) "
                          "generated by antsCorticalThickness.sh command "
                          "(transforms are accessed from same directory)"),
                    metavar='STR')
parser.add_argument("--cpus",
                    help='number of processors to use (default: 1)',
                    type=int, default=1, metavar='INT')
parser.add_argument("-v", "--version", help="version number",
                    action='version', version='%(prog)s 1.0')
shp_args.add_argument("--fundi", action='store_true',
                      help="extract, identify, and measure fundi in"
                           " sulci [turned off by default because untested]")
shp_args.add_argument("--moments",
                      help="Zernike moments order per label/feature "
                           "(ex: 10; off by default due to occasional "
                           "memory leak)",
                      default=0, type=int, metavar='INT')
shp_args.add_argument("--spectra",
                      help="Laplace-Beltrami spectrum eigenvalues "
                           "per label/feature (default: 10)",
                      default=10, type=int, metavar='INT')
out_args.add_argument("--out",
                      help='output folder (if not $HOME/mindboggled)',
                      default=os.path.join(os.environ['HOME'],
                                           'mindboggled'), metavar='STR')
out_args.add_argument("--working",
                      help="working folder (if not $HOME/mindboggle_working)",
                      default=os.path.join(os.environ['HOME'],
                                           'mindboggle_working'),
                      metavar='STR')
out_args.add_argument("--cache",
                      help='download folder (if not $HOME/mindboggle_cache)',
                      default=os.path.join(os.environ['HOME'],
                                           'mindboggle_cache'), metavar='STR')
out_args.add_argument("--graph",
                      help='plot workflow graph: "hier", "flat", "exec"',
                      choices=['hier', 'flat', 'exec'],
                      default='hier', metavar='STR')

out_args.add_argument("--save_only_tables", action='store_true',
                      help="save only tables to free up space")
out_args.add_argument("--no_volumes", action='store_true',
                      help="no volume labels, features, or shape tables")
out_args.add_argument("--no_surfaces", action='store_true',
                      help="no surface labels, features, or shape tables")
out_args.add_argument("--no_labels", action='store_true',
                      help="no surface or volume labels")
out_args.add_argument("--no_shapes", action='store_true',
                      help="no shape tables of surface labels or features")
out_args.add_argument("--no_folds", action='store_true',
                      help="no folds")
out_args.add_argument("--no_sulci", action='store_true',
                      help="no sulci from folds")
out_args.add_argument("--no_points", action='store_true',
                      help="no table of per-vertex surface shape measures")
out_args.add_argument("--no_moments", action='store_true',
                      help="no Zernike moments per surface label/feature")
out_args.add_argument("--no_spectra", action='store_true',
                      help="no Laplace-Beltrami per surface label/feature")
out_args.add_argument("--no_thickness", action='store_true',
                      help="no volume-based cortical label thicknesses")
out_args.add_argument("--no_surfaces_in_mni", action='store_true',
                      help="no cortical surfaces in MNI152 space")

adv_args.add_argument("--my_atlas",
                      help=("different atlas than OASIS-TRT-20 jointfusion "
                            "atlas; must follow CMA/DKT31 non/cortical "
                            "labeling protocols, be in MNI152 space, "
                            "and correspond to Atropos template (if --ants)"),
                      metavar='STR')
adv_args.add_argument("--my_atlases",
                      help=("extra labeling volume atlas(es) in MNI152 "
                            "space; use any label numbers (disregard names) "
                            "in return_numbers_names_colors() function"),
                      nargs='+', metavar='')
adv_args.add_argument("--my_graywhite",
                      help=("use this gray/white matter file (ex: edited "
                            "version of Mindboggle's gray/white output); "
                            "must still call --ants for transforms"),
                      metavar='STR')
adv_args.add_argument("--volume_labels",
                      help=(argparse.SUPPRESS),
                      choices=['wmparc', 'aparc+aseg'],
                      default='wmparc', metavar='STR')
adv_args.add_argument("--surface_labels",
                      help=(argparse.SUPPRESS),
                      choices=['freesurfer', 'manual'],
                      default='freesurfer', metavar='STR')
adv_args.add_argument("--my_transform",
                      help=("different affine transform from Atropos "
                            "template to MNI152 space (if OASIS-30 "
                            "template not used to get --ants output); "
                            "use antsAffine.sh ITK transform format"),
                      metavar='STR')
adv_args.add_argument("--plugin", dest="plugin",
                      default='Linear',
                      help="Nipype plugin to use, such as: --plugin PBS")
adv_args.add_argument("--plugin_args", dest="plugin_args",
                      help="Plugin arguments in dictionary form, such as:"
                           " --plugin_args \"dict(qsub_args='-q many')\"")
args = parser.parse_args()

# ----------------------------------------------------------------------------
# Data arguments:
# ----------------------------------------------------------------------------
DATA = args.DATA
if not os.path.isdir(DATA):
    raise IOError("Please provide correct path to DATA.")
subject = os.path.basename(DATA)
subjects_dir = os.path.dirname(DATA)
if not subjects_dir:
    if os.environ['SUBJECTS_DIR']:
        subjects_dir = os.environ['SUBJECTS_DIR']
    else:
        raise IOError("Please provide path to DATA or set"
                      " $SUBJECTS_DIR variable.")
if args.my_atlas:
    my_atlas = args.my_atlas
else:
    my_atlas = None
if args.my_graywhite:
    my_graywhite = args.my_graywhite
else:
    my_graywhite = None
if args.my_transform:
    my_transform = args.my_transform
else:
    my_transform = None
use_FS_inputs = True
do_input_vtk = False  # Load VTK surfaces directly (not FreeSurfer surfaces)
do_input_fs_labels = False  # Load nifti (not FreeSurfer mgh file)

# ----------------------------------------------------------------------------
# Label, feature, and shape arguments:
# ----------------------------------------------------------------------------
volume_labels = args.volume_labels
surface_labels = args.surface_labels
if args.ants:
    ants_seg = args.ants
    use_ants = True
else:
    use_ants = False
if args.no_labels:
    do_label = False
else:
    do_label = True
if args.no_shapes:
    do_shapes = False
else:
    do_shapes = True
if args.save_only_tables:
    save_all = False
else:
    save_all = True

# FreeSurfer shapes:
if do_shapes and use_FS_inputs:
    do_freesurfer_thickness = True
    do_freesurfer_curvature = True
    do_freesurfer_sulc = True
else:
    do_freesurfer_thickness = False  # Include FreeSurfer's thickness measure
    do_freesurfer_curvature = False  # Include FreeSurfer's curvature (curv)
    do_freesurfer_sulc = False  # Include FreeSurfer's convexity (sulc)

# More on/off settings:
if args.no_folds:
    save_folds = False
else:
    save_folds = True
if args.no_sulci:
    do_sulci = False
#    do_fundi = False
else:
    do_sulci = True
#    if args.no_fundi:
#        do_fundi = False
#    else:
#        do_fundi = True
if args.fundi:
    do_fundi = True
else:
    do_fundi = False
if args.no_points:
    do_points = False
else:
    do_points = True
if args.no_surfaces_in_mni:
    do_surfaces_in_mni = False
else:
    do_surfaces_in_mni = True
if args.no_thickness:
    do_thickinthehead = False
else:
    do_thickinthehead = True
if args.no_moments:
    do_moments = False
else:
    do_moments = True
if args.no_spectra:
    do_spectra = False
else:
    do_spectra = True

# Set Laplace-Beltrami spectra:
if do_spectra and spectra <= 0:
    spectra = 10

# Only compute Zernike moments if set:
moments = args.moments
if moments <= 0:
    do_moments = False

# Extra labeling atlases in MNI space:
atlases = args.my_atlases
add_atlas_names = []
if atlases:
    if isinstance(atlases, str):
        atlases = [atlases]
    for add_atlas in atlases:
        add_atlas_names.append(os.path.basename(add_atlas).split('.')[0])

# ============================================================================
#
#   Hidden arguments: paths, labels and template data
#
# ============================================================================
ccode_path = os.environ['vtk_cpp_tools']  # Mindboggle C++ code directory
overwrite_cerebrum_with_cerebellum = True
fill_noncortex_with_ants_labels = False
do_smooth_fundi = False
# ----------------------------------------------------------------------------
# Hashes to verify retrieved data, and output, working, and cache directories:
# ----------------------------------------------------------------------------
hashes, url, cache_env, cache = hashes_url()
if args.cache:
    cache = args.cache
elif cache_env in os.environ.keys():
    cache = os.environ[cache_env]
if args.working:
    working = os.path.join(args.working, subject)
else:
    working = os.path.join(os.environ['HOME'], 'mindboggle_working', subject)
if not os.path.isdir(args.out):
    print("Create missing output directory: {0}".format(args.out))
    os.makedirs(args.out)
if not os.path.isdir(working):
    print("Create missing working directory: {0}".format(working))
    os.makedirs(working)
if not os.path.isdir(cache):
    print("Create missing cache directory: {0}".format(cache))
    os.makedirs(cache)
# ----------------------------------------------------------------------------
# Labeling protocol information and volume atlases:
# ----------------------------------------------------------------------------
dkt = DKTprotocol()
atlas_volume = 'OASIS-TRT-20_jointfusion_DKT31_CMA_labels_in_MNI152_v2.nii.gz'
atropos_to_MNI152_affine = 'OASIS-30_Atropos_template_to_MNI152_affine.txt'
# ----------------------------------------------------------------------------
# Surface atlas labels:
# - 'manual': manual edits
# - FUTURE: <'adjusted': manual edits after automated alignment to fundi>
# ----------------------------------------------------------------------------
surface_atlas_type = 'manual'
#modify_surface_labels = False

# ============================================================================
#
#   Basic functions
#
# ============================================================================

def split_list_pair(List):
    element1 = List[0]
    element2 = List[1]
    return element1, element2

def first_string_containing_substring(substring, List):
    first_matching_string = [x for x in List if substring in x][0]
    return first_matching_string

# ============================================================================
#
#   Initialize workflow inputs and outputs
#
# ============================================================================
mbFlow = Workflow(name='Mindboggle')
mbFlow.base_dir = working

# ----------------------------------------------------------------------------
# Iterate inputs over hemispheres and atlases
# (surfaces are assumed to take the form: lh.pial or lh.pial.vtk)
# ----------------------------------------------------------------------------
if add_atlas_names:
    InputVolumeAtlases = Node(name='Input_volume_atlases',
                           interface=IdentityInterface(fields=['atlas']))
    InputVolumeAtlases.iterables = ('atlas', add_atlas_names)
InputHemis = Node(name='Input_hemispheres',
                  interface=IdentityInterface(fields=['hemi']))
hemis = ['lh', 'rh']
InputHemis.iterables = ('hemi', hemis)
# ----------------------------------------------------------------------------
# Outputs and name substitutions
# ----------------------------------------------------------------------------
Sink = Node(DataSink(), name='Results')
Sink.inputs.base_directory = args.out
Sink.inputs.container = subject

if my_graywhite:
    seg_in = os.path.basename(my_graywhite)
else:
    seg_in = 'combined_segmentations.nii.gz'
mgz = volume_labels + '.mgz.nii.gz'
ants_str = 'ants_labels.nii.gz'
fs_filled_fs = '{0}_to_{0}_through_{0}_to_{0}_through_{0}'.format(mgz)
fs_filled = '{0}_to_{0}_through_{1}_to_{0}_through_{1}'.format(mgz, seg_in)
ants_filled_ants = '{0}_to_{1}_to_{1}_through_{0}'.format(mgz, ants_str)


ants_filled = '{0}_to_{1}_to_{1}_through_{2}'.format(mgz, ants_str, seg_in)


fs_filled_fs_rename = 'freesurfer_' + volume_labels + \
                      '_labels_in_freesurfer_graywhite.nii.gz'
fs_filled_rename = 'freesurfer_' + volume_labels + \
                   '_labels_in_hybrid_graywhite.nii.gz'
ants_filled_ants_rename = 'ants_labels_in_ants_graywhite.nii.gz'
ants_filled_rename = 'ants_labels_in_hybrid_graywhite.nii.gz'

Sink.inputs.substitutions = [ ('lh.', ''), ('rh.', ''),
    ('_hemi_lh', 'left_cortical_surface'),
    ('_hemi_rh', 'right_cortical_surface'),
    ('pial.', ''),
    ('thickness.vtk', 'freesurfer_thickness.vtk'),
    ('curv.vtk', 'freesurfer_curvature.vtk'),
    ('sulc.vtk', 'freesurfer_sulc.vtk'),
    ('relabeled_aparc.vtk', 'freesurfer_cortex_labels.vtk'),
    (fs_filled_fs, fs_filled_fs_rename),
    (fs_filled, fs_filled_rename),
    (ants_filled_ants, ants_filled_ants_rename),
    (ants_filled, ants_filled_rename),
    ('smooth_skeletons.vtk', 'smooth_fundi.vtk')]
# Substitutions for additional atlas names:
Sink.inputs.regexp_substitutions = [
    (r'/_atlas_(.*)/ants_added_atlas_labels.nii.gz', r'/\1_labels.nii.gz'),
    (r'/_atlas_(.*)/volume_for_each_added_label.csv',
     r'/volume_for_each_\1_label.csv'),
    (r'/affine_(.*).vtk', r'/cortex_in_MNI152_space.vtk')]

# ----------------------------------------------------------------------------
# Affine transform from Atropos template to MNI152 space:
# ----------------------------------------------------------------------------
if my_transform:
    affine_template2mni = my_transform
else:
    affine_template2mni = fetch_check_data(atropos_to_MNI152_affine,
                                           url, hashes, cache_env, cache)
# ----------------------------------------------------------------------------
# Atlas labels:
# ----------------------------------------------------------------------------
if do_label and not my_atlas:
    FetchAtlas = Node(name='Fetch_Mindboggle_atlas',
                      interface=Fn(function=fetch_check_data,
                                   input_names=['data_file',
                                                'url',
                                                'hashes',
                                                'cache_env',
                                                'cache',
                                                'return_missing',
                                                'lookup'],
                                   output_names=['data_path']))
    mbFlow.add_nodes([FetchAtlas])
    FetchAtlas.inputs.data_file = atlas_volume
    FetchAtlas.inputs.url = url
    FetchAtlas.inputs.hashes = hashes
    FetchAtlas.inputs.cache_env = cache_env
    FetchAtlas.inputs.cache = cache
    FetchAtlas.inputs.return_missing = False
    FetchAtlas.inputs.lookup = True

# ----------------------------------------------------------------------------
# ANTs data:
# ----------------------------------------------------------------------------
if use_ants:
    FetchAnts = Node(name='Fetch_ants_data',
                     interface=Fn(function=fetch_ants_data,
                                  input_names=['segmented_file',
                                               'use_ants_transforms'],
                                  output_names=['mask',
                                                'segments',
                                                'affine_subject2template',
                                                'warp_subject2template',
                                                'affine_template2subject',
                                                'warp_template2subject']))
    mbFlow.add_nodes([FetchAnts])
    FetchAnts.inputs.segmented_file = ants_seg
    FetchAnts.inputs.use_ants_transforms = True
    # ------------------------------------------------------------------------
    # For transforming volume labels --
    # Make list of ANTs MNI152-to-subject nonlinear transforms
    # to use Apply_ants_transforms:
    #
    # Note regarding Apply_ants_transforms:
    # To warp the subject image to the template, one would call
    # Apply_ants_transforms...-i ${subject} -r ${template}
    #                       -t ${prefix}SubjectToTemplate1Warp.nii.gz
    #                       -t ${prefix}SubjectToTemplate0GenericAffine.mat
    # To warp the template image to the subject, one would call
    # Apply_ants_transforms...-i ${template} -r ${subject}
    #                       -t ${prefix}TemplateToSubject1GenericAffine.mat
    #                       -t ${prefix}TemplateToSubject0Warp.nii.gz
    # ------------------------------------------------------------------------
    ListSubject2mniTransforms = Node(name='List_subject_to_mni_transforms',
                                     interface=Fn(function=list_strings,
                                          input_names=['string1',
                                                       'string2',
                                                       'string3',
                                                       'string4'],
                                          output_names=['string_list']))
    mbFlow.connect(FetchAnts, 'affine_template2subject',
                   ListSubject2mniTransforms, 'string1')
    mbFlow.connect(FetchAnts, 'warp_template2subject',
                   ListSubject2mniTransforms, 'string2')
    ListSubject2mniTransforms.inputs.string3 = affine_template2mni
    ListSubject2mniTransforms.inputs.string4 = ''
    warp_inverse_Booleans = [False, False, True]  # Boolean list
    # ------------------------------------------------------------------------
    # For transforming surface points --
    # Make list of subject-to-MNI affine transforms
    # to use Apply_ants_transformsToPoints:
    #
    # Note regarding Apply_ants_transformsToPoints:
    # Points are transformed in the OPPOSITE direction of images,
    # so you pass the inverse of what is needed to warp the images.
    # Note 2: Don't forget to switch the order of the affine transforms!
    # ------------------------------------------------------------------------
    ListSubject2mniAffineTransforms = Node(
                                name='List_subject_to_mni_affine_transforms',
                                interface=Fn(function=list_strings,
                                             input_names=['string1',
                                                          'string2',
                                                          'string3',
                                                          'string4'],
                                             output_names=['string_list']))
    mbFlow.connect(FetchAnts, 'affine_subject2template',
                   ListSubject2mniAffineTransforms, 'string1')
    ListSubject2mniAffineTransforms.inputs.string2 = affine_template2mni
    ListSubject2mniAffineTransforms.inputs.string3 = ''
    ListSubject2mniAffineTransforms.inputs.string4 = ''
    inverse_Booleans = [1, 1]  # list of ones/zeros for True/False

# ============================================================================
# ----------------------------------------------------------------------------
#
#   Surface workflows
#
# ----------------------------------------------------------------------------
# ============================================================================
if not args.no_surfaces:
    # ------------------------------------------------------------------------
    # Location and structure of the surface inputs:
    # ------------------------------------------------------------------------
    use_white_surface = False
    if use_white_surface:
        Surf = Node(name='Surfaces',
                    interface=DataGrabber(infields=['subject', 'hemi'],
                                          outfields=['surface_files',
                                                     'white_surface_files'],
                                          sort_filelist=False))
    else:
        Surf = Node(name='Surfaces',
                    interface=DataGrabber(infields=['subject', 'hemi'],
                                          outfields=['surface_files'],
                                          sort_filelist=False))
    Surf.inputs.base_directory = subjects_dir
    Surf.inputs.template = '%s/surf/%s.%s'
    Surf.inputs.template_args['surface_files'] = [['subject', 'hemi', 'pial']]
    if use_white_surface:
        Surf.inputs.template_args['white_surface_files'] = [['subject',
                                                             'hemi', 'white']]
    #Surf.inputs.template_args['sphere_files'] = [['subject','hemi','sphere']]
    if do_freesurfer_thickness:
        Surf.inputs.template_args['freesurfer_thickness_files'] = \
            [['subject', 'hemi', 'thickness']]
    if do_freesurfer_curvature:
        Surf.inputs.template_args['freesurfer_curvature_files'] = \
            [['subject', 'hemi', 'curv']]
    if do_freesurfer_sulc:
        Surf.inputs.template_args['freesurfer_sulc_files'] = \
            [['subject', 'hemi', 'sulc']]

    Surf.inputs.subject = subject
    mbFlow.connect(InputHemis, 'hemi', Surf, 'hemi')
    # ------------------------------------------------------------------------
    # Convert surfaces to VTK:
    # ------------------------------------------------------------------------
    if not do_input_vtk:
        Surf2vtk = Node(name='Surface_to_vtk',
                        interface=Fn(function=freesurfer_surface_to_vtk,
                                     input_names=['surface_file',
                                                  'output_vtk'],
                                     output_names=['output_vtk']))
        mbFlow.connect(Surf, 'surface_files', Surf2vtk, 'surface_file')
        Surf2vtk.inputs.output_vtk = ''
        if use_white_surface:
            ConvertWhiteSurf = Surf2vtk.clone('Gray-white_surface_to_vtk')
            mbFlow.add_nodes([ConvertWhiteSurf])
            mbFlow.connect(Surf, 'white_surface_files',
                           ConvertWhiteSurf, 'surface_file')
    # ------------------------------------------------------------------------
    # Evaluation inputs: location and structure of atlas surfaces:
    # ------------------------------------------------------------------------
    if surface_labels == 'manual' and do_label:
        SurfaceAtlas = Node(name='Surface_atlas',
                            interface=DataGrabber(infields=['subject','hemi'],
                                                  outfields=['atlas_file'],
                                                  sort_filelist=False))
        SurfaceAtlas.inputs.base_directory = subjects_dir
        SurfaceAtlas.inputs.template = '%s/label/%s.labels.DKT31.' +\
                                       surface_atlas_type + '.vtk'
        SurfaceAtlas.inputs.template_args['atlas_file'] = [['subject','hemi']]

        SurfaceAtlas.inputs.subject = subject
        mbFlow.connect(InputHemis, 'hemi', SurfaceAtlas, 'hemi')

    # ========================================================================
    #
    #   Surface labels
    #
    # ========================================================================
    if do_label:
        SurfLabelFlow = Workflow(name='Surface_labels')

        # ====================================================================
        # Initialize labels with the DKT classifier atlas
        # NOTE: This can now be done by running FreeSurfer's recon-all
        #       with "-gcs DKTatlas40.gcs"
        # ====================================================================
        # surface_classifier = DKTatlas40
        # if surface_labels == 'atlas' and use_FS_inputs:
        #     # --------------------------------------------------------------
        #     # Label brain with DKT atlas using FreeSurfer's mris_ca_label:
        #     # --------------------------------------------------------------
        #     Classifier = Node(name='mris_ca_label',
        #                       interface=Fn(function=label_with_classifier,
        #                                    input_names=['subject',
        #                                                 'hemi',
        #                                                 'left_classifier',
        #                                                 'right_classifier',
        #                                                 'annot_file',
        #                                                 'subjects_directory'],
        #                                    output_names=['annot_file']))
        #     SurfLabelFlow.add_nodes([Classifier])
        #     Classifier.inputs.subject = subject
        #     mbFlow.connect(InputHemis, 'hemi',
        #                    SurfLabelFlow, 'mris_ca_label.hemi')
        #     left_classifier_file = 'lh.' + surface_classifier + '.gcs'
        #     right_classifier_file = 'rh.' + surface_classifier + '.gcs'
        #     left_classifier = fetch_check_data(left_classifier_file, url,
        #                                     hashes, cache_env, cache)
        #     right_classifier = fetch_check_data(right_classifier_file, url,
        #                                      hashes, cache_env, cache)
        #     Classifier.inputs.left_classifier = left_classifier
        #     Classifier.inputs.right_classifier = right_classifier
        #     Classifier.inputs.annot_file = ''
        #     Classifier.inputs.subjects_directory = subjects_dir
        #     # --------------------------------------------------------------
        #     # Convert .annot file to VTK format:
        #     # --------------------------------------------------------------
        #     Classifier2vtk = Node(name='annot_to_vtk',
        #                           interface=Fn(function=freesurfer_annot_to_vtk,
        #                                        input_names=['annot_file',
        #                                                     'vtk_file'],
        #                                        output_names=['labels',
        #                                                      'output_vtk']))
        #     SurfLabelFlow.add_nodes([Classifier2vtk])
        #     SurfLabelFlow.connect(Classifier, 'annot_file',
        #                           Classifier2vtk, 'annot_file')
        #     if do_input_vtk:
        #         mbFlow.connect(Surf, 'surface_files',
        #                        SurfLabelFlow, 'annot_to_vtk.vtk_file')
        #     else:
        #         mbFlow.connect(Surf2vtk, 'output_vtk',
        #                        SurfLabelFlow, 'annot_to_vtk.vtk_file')
        #     #if save_all:
        #     #    mbFlow.connect(SurfLabelFlow, 'annot_to_vtk.output_vtk',
        #     #                   Sink, 'labels.@DKT_surface')
        #     plug = 'annot_to_vtk.output_vtk'
        #     plug1 = Classifier2vtk
        #     plug2 = 'output_vtk'

        # ====================================================================
        # Initialize labels with FreeSurfer
        # ====================================================================
        if surface_labels == 'freesurfer' and use_FS_inputs:
            # ----------------------------------------------------------------
            # Location and structure of the FreeSurfer label inputs:
            # ----------------------------------------------------------------
            if surface_labels == 'freesurfer':
                Annot = Node(name='Freesurfer_annot',
                             interface=DataGrabber(infields=['subject',
                                                             'hemi'],
                                                   outfields=['annot_files'],
                                                   sort_filelist=False))
                Annot.inputs.base_directory = subjects_dir
                Annot.inputs.template = '%s/label/%s.aparc.annot'
                Annot.inputs.template_args['annot_files'] = [['subject',
                                                              'hemi']]
                Annot.inputs.subject = subject
                mbFlow.connect(InputHemis, 'hemi', Annot, 'hemi')
            # ----------------------------------------------------------------
            # Convert Annot to VTK format:
            # ----------------------------------------------------------------
            Annot2vtk = Node(name='Freesurfer_annot_to_vtk',
                             interface=Fn(function=freesurfer_annot_to_vtk,
                                          input_names=['annot_file',
                                                       'vtk_file'],
                                          output_names=['labels',
                                                        'output_vtk']))
            SurfLabelFlow.add_nodes([Annot2vtk])
            mbFlow.connect(Annot, 'annot_files', SurfLabelFlow,
                           'Freesurfer_annot_to_vtk.annot_file')
            if do_input_vtk:
                mbFlow.connect(Surf, 'surface_files', SurfLabelFlow,
                               'Freesurfer_annot_to_vtk.vtk_file')
            else:
                mbFlow.connect(Surf2vtk, 'output_vtk', SurfLabelFlow,
                               'Freesurfer_annot_to_vtk.vtk_file')
            plug = 'Freesurfer_annot_to_vtk.output_vtk'
            plug1 = Annot2vtk
            plug2 = 'output_vtk'

        # ====================================================================
        # Skip label initialization and process manual (atlas) labels
        # ====================================================================
        elif surface_labels == 'manual':
            ManualSurfLabels = Node(name='Manual_surface_labels',
                                    interface=Fn(function=read_vtk,
                                                 input_names=['input_vtk',
                                                              'return_first',
                                                              'return_array'],
                                                 output_names=['faces',
                                                               'lines',
                                                               'indices',
                                                               'points',
                                                               'npoints',
                                                               'scalars',
                                                               'scalar_names',
                                                               'input_vtk']))
            SurfLabelFlow.add_nodes([ManualSurfLabels])
            mbFlow.connect(SurfaceAtlas, 'atlas_file',
                           SurfLabelFlow, 'Manual_surface_labels.input_vtk')
            ManualSurfLabels.inputs.return_first = 'True'
            ManualSurfLabels.inputs.return_array = 'False'
            plug = 'Manual_surface_labels.input_vtk'
            plug1 = ManualSurfLabels
            plug2 = 'input_vtk'

        # ====================================================================
        # Convert surface label numbers to volume DKT31 label numbers
        # ====================================================================
        ReindexLabels = Node(name='Reindex_labels',
                             interface=Fn(function=relabel_surface,
                                          input_names=['vtk_file',
                                                       'hemi',
                                                       'old_labels',
                                                       'new_labels',
                                                       'erase_remaining',
                                                       'erase_labels',
                                                       'erase_value',
                                                       'output_file'],
                                          output_names=['output_file']))
        SurfLabelFlow.add_nodes([ReindexLabels])
        SurfLabelFlow.connect(plug1, plug2, ReindexLabels, 'vtk_file')
        mbFlow.connect(InputHemis, 'hemi',
                       SurfLabelFlow, 'Reindex_labels.hemi')
        ReindexLabels.inputs.old_labels = dkt.DKT31_numbers
        ReindexLabels.inputs.new_labels = []
        ReindexLabels.inputs.erase_remaining = True
        ReindexLabels.inputs.erase_labels = [0]
        ReindexLabels.inputs.erase_value = -1
        ReindexLabels.inputs.output_file = ''
        if save_all:
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           Sink, 'labels.@surface')

    # ========================================================================
    #
    #   Surface shape measurements
    #
    # ========================================================================
    if do_shapes:
        WholeSurfShapeFlow = Workflow(name='Surface_shapes')
        # --------------------------------------------------------------------
        # Measure surface area:
        # --------------------------------------------------------------------
        SurfaceArea = Node(name='Surface_area',
                           interface=Fn(function=area,
                                        input_names=['command',
                                                     'surface_file'],
                                        output_names=['area_file']))
        area_command = os.path.join(ccode_path, 'area', 'PointAreaMain')
        SurfaceArea.inputs.command = area_command
        # --------------------------------------------------------------------
        # Measure surface travel depth:
        # --------------------------------------------------------------------
        TravelDepth = Node(name='Travel_depth',
                           interface=Fn(function=travel_depth,
                                        input_names=['command',
                                                     'surface_file'],
                                        output_names=['depth_file']))
        WholeSurfShapeFlow.add_nodes([TravelDepth])
        TravelDepth.inputs.command = os.path.join(ccode_path,
                                                  'travel_depth',
                                                  'TravelDepthMain')
        # --------------------------------------------------------------------
        # Rescale surface travel depth:
        # --------------------------------------------------------------------
        if do_fundi:
            RescaleTravelDepth = Node(name='Rescale_travel_depth',
                                interface=Fn(function=rescale_by_neighborhood,
                                     input_names=['input_vtk',
                                                  'indices',
                                                  'nedges',
                                                  'p',
                                                  'set_max_to_1',
                                                  'save_file',
                                                  'output_filestring'],
                                     output_names=['rescaled_scalars',
                                                   'rescaled_scalars_file']))
            WholeSurfShapeFlow.add_nodes([RescaleTravelDepth])
            WholeSurfShapeFlow.connect(TravelDepth, 'depth_file',
                                       RescaleTravelDepth, 'input_vtk')
            RescaleTravelDepth.inputs.indices = []
            RescaleTravelDepth.inputs.nedges = 10
            RescaleTravelDepth.inputs.p = 99
            RescaleTravelDepth.inputs.set_max_to_1 = True
            RescaleTravelDepth.inputs.save_file = True
            RescaleTravelDepth.inputs.output_filestring = \
                'travel_depth_rescaled'
        # --------------------------------------------------------------------
        # Measure surface geodesic depth:
        # --------------------------------------------------------------------
        GeodesicDepth = Node(name='Geodesic_depth',
                             interface=Fn(function=geodesic_depth,
                                          input_names=['command',
                                                       'surface_file'],
                                          output_names=['depth_file']))
        GeodesicDepth.inputs.command = os.path.join(ccode_path,
                                                    'geodesic_depth',
                                                    'GeodesicDepthMain')
        # --------------------------------------------------------------------
        # Measure surface curvature:
        # --------------------------------------------------------------------
        CurvNode = Node(name='Curvature',
                        interface=Fn(function=curvature,
                             input_names=['command',
                                          'method',
                                          'arguments',
                                          'surface_file'],
                             output_names=['mean_curvature_file',
                                           'gauss_curvature_file',
                                           'max_curvature_file',
                                           'min_curvature_file',
                                           'min_curvature_vector_file']))
        CurvNode.inputs.command = os.path.join(ccode_path,
                                               'curvature',
                                               'CurvatureMain')
        CurvNode.inputs.method = 2
        CurvNode.inputs.arguments = '-n 0.7'
        # --------------------------------------------------------------------
        # Convert FreeSurfer surface measures to VTK:
        # --------------------------------------------------------------------
        if do_freesurfer_curvature:
            FScurv2vtk = Node(name='Freesurfer_curv_to_vtk',
                           interface=Fn(function=freesurfer_curvature_to_vtk,
                                        input_names=['surface_file',
                                                     'vtk_file',
                                                     'output_vtk'],
                                        output_names=['output_vtk']))
            WholeSurfShapeFlow.add_nodes([FScurv2vtk])
            mbFlow.connect(Surf, 'freesurfer_curvature_files',
                           WholeSurfShapeFlow, 
                           'Freesurfer_curv_to_vtk.surface_file')
            mbFlow.connect(Surf2vtk, 'output_vtk',
                           WholeSurfShapeFlow, 
                           'Freesurfer_curv_to_vtk.vtk_file')
            FScurv2vtk.inputs.output_vtk = ''
            if save_all:
                mbFlow.connect(WholeSurfShapeFlow, 
                               'Freesurfer_curv_to_vtk.output_vtk',
                               Sink, 'shapes.@freesurfer_curvature')
        if do_freesurfer_sulc:
            FSsulc2vtk = Node(name='Freesurfer_sulc_to_vtk',
                           interface=Fn(function=freesurfer_curvature_to_vtk,
                                        input_names=['surface_file',
                                                     'vtk_file',
                                                     'output_vtk'],
                                        output_names=['output_vtk']))
            WholeSurfShapeFlow.add_nodes([FSsulc2vtk])
            mbFlow.connect(Surf, 'freesurfer_sulc_files',
                           WholeSurfShapeFlow, 
                           'Freesurfer_sulc_to_vtk.surface_file')
            mbFlow.connect(Surf2vtk, 'output_vtk',
                           WholeSurfShapeFlow, 
                           'Freesurfer_sulc_to_vtk.vtk_file')
            FSsulc2vtk.inputs.output_vtk = ''
            if save_all:
                mbFlow.connect(WholeSurfShapeFlow, 
                               'Freesurfer_sulc_to_vtk.output_vtk',
                               Sink, 'shapes.@freesurfer_sulc')
        if do_freesurfer_thickness:
            FSthick2vtk = Node(name='Freesurfer_thickness_to_vtk',
                            interface=Fn(function=freesurfer_curvature_to_vtk,
                                         input_names=['surface_file',
                                                      'vtk_file',
                                                      'output_vtk'],
                                         output_names=['output_vtk']))
            WholeSurfShapeFlow.add_nodes([FSthick2vtk])
            mbFlow.connect(Surf, 'freesurfer_thickness_files',
                           WholeSurfShapeFlow,
                           'Freesurfer_thickness_to_vtk.surface_file')
            mbFlow.connect(Surf2vtk, 'output_vtk',
                           WholeSurfShapeFlow, 
                           'Freesurfer_thickness_to_vtk.vtk_file')
            FSthick2vtk.inputs.output_vtk = ''
            if save_all:
                mbFlow.connect(WholeSurfShapeFlow, 
                               'Freesurfer_thickness_to_vtk.output_vtk',
                               Sink, 'shapes.@freesurfer_thickness')
        # --------------------------------------------------------------------
        # Connect nodes:
        # --------------------------------------------------------------------
        WholeSurfShapeFlow.add_nodes([SurfaceArea, GeodesicDepth, CurvNode])
        if do_input_vtk:
            mbFlow.connect([(Surf, WholeSurfShapeFlow,
                             [('surface_files','Surface_area.surface_file'),
                              ('surface_files','Travel_depth.surface_file'),
                              ('surface_files','Geodesic_depth.surface_file'),
                              ('surface_files','Curvature.surface_file')])])
        else:
            mbFlow.connect([(Surf2vtk, WholeSurfShapeFlow,
                               [('output_vtk', 'Surface_area.surface_file'),
                                ('output_vtk', 'Travel_depth.surface_file'),
                                ('output_vtk', 'Geodesic_depth.surface_file'),
                                ('output_vtk', 'Curvature.surface_file')])])
        if save_all:
            mbFlow.connect([(WholeSurfShapeFlow, Sink,
              [('Surface_area.area_file', 'shapes.@surface_area'),
               ('Travel_depth.depth_file', 'shapes.@travel_depth'),
               ('Geodesic_depth.depth_file', 'shapes.@geodesic_depth'),
               ('Curvature.mean_curvature_file', 'shapes.@mean_curvature')])])

    # ========================================================================
    #
    #   Surface feature extraction
    #
    # ========================================================================
    if do_sulci or do_fundi:
        SurfFeatureFlow = Workflow(name='Surface_features')

        # ====================================================================
        # Folds and sulci
        # ====================================================================
        if do_sulci or do_fundi:
            # ----------------------------------------------------------------
            # Folds:
            # ----------------------------------------------------------------
            FoldsNode = Node(name='Folds',
                             interface=Fn(function=extract_folds,
                                          input_names=['depth_file',
                                                       'min_vertices',
                                                       'min_fold_size',
                                                       'do_fill_holes',
                                                       'min_hole_depth',
                                                       'save_file'],
                                          output_names=['folds',
                                                        'n_folds',
                                                        'depth_threshold',
                                                        'bins',
                                                        'bin_edges',
                                                        'folds_file']))
            SurfFeatureFlow.add_nodes([FoldsNode])
            mbFlow.connect(WholeSurfShapeFlow, 'Travel_depth.depth_file',
                           SurfFeatureFlow, 'Folds.depth_file')
            FoldsNode.inputs.min_vertices = 10000
            FoldsNode.inputs.min_fold_size = 50
            FoldsNode.inputs.do_fill_holes = False
            FoldsNode.inputs.min_hole_depth = 0.001
            FoldsNode.inputs.save_file = True
            if save_folds and save_all:
               mbFlow.connect(SurfFeatureFlow, 'Folds.folds_file',
                              Sink, 'features.@folds')
            # ----------------------------------------------------------------
            # Sulci:
            # ----------------------------------------------------------------
            SulciNode = Node(name='Sulci',
                             interface=Fn(function=extract_sulci,
                                          input_names=['labels_file',
                                                       'folds_or_file',
                                                       'hemi',
                                                       'min_boundary',
                                                       'sulcus_names',
                                                       'verbose'],
                                          output_names=['sulci',
                                                        'n_sulci',
                                                        'sulci_file']))
            SurfFeatureFlow.add_nodes([SulciNode])
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           SurfFeatureFlow, 'Sulci.labels_file')
            SurfFeatureFlow.connect(FoldsNode, 'folds',
                                    SulciNode, 'folds_or_file')
            mbFlow.connect(InputHemis, 'hemi', SurfFeatureFlow, 'Sulci.hemi')
            SulciNode.inputs.min_boundary = 1
            SulciNode.inputs.sulcus_names = dkt.sulcus_names
            if save_all:
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci_file',
                               Sink, 'features.@sulci')
            SulciNode.inputs.verbose = True

        # ====================================================================
        # Fundi
        # ====================================================================
        if do_fundi:
            # ----------------------------------------------------------------
            # Extract a fundus per fold:
            # ----------------------------------------------------------------
            FundusPerFold = Node(name='Fundus_per_fold',
                                 interface=Fn(function=extract_fundi,
                                      input_names=['folds',
                                                   'curv_file',
                                                   'depth_file',
                                                   'min_separation',
                                                   'erode_ratio',
                                                   'erode_min_size',
                                                   'save_file',
                                                   'verbose'],
                                      output_names=['fundus_per_fold',
                                                    'n_fundi_in_folds',
                                                    'fundus_per_fold_file']))
            SurfFeatureFlow.connect(FoldsNode, 'folds', 
                                    FundusPerFold, 'folds')
            mbFlow.connect([(WholeSurfShapeFlow, SurfFeatureFlow,
                           [('Curvature.mean_curvature_file',
                             'Fundus_per_fold.curv_file'),
                            ('Rescale_travel_depth.rescaled_scalars_file',
                             'Fundus_per_fold.depth_file')])])
            FundusPerFold.inputs.min_separation = 10
            FundusPerFold.inputs.erode_ratio = 0.10
            FundusPerFold.inputs.erode_min_size = 10
            FundusPerFold.inputs.save_file = False
            FundusPerFold.inputs.verbose = True
            #if save_all:
            #    mbFlow.connect(SurfFeatureFlow,
            #                   'Fundus_per_fold.fundus_per_fold_file',
            #                   Sink, 'features.@fundus_per_fold')

            if do_smooth_fundi:
                # ------------------------------------------------------------
                # Compute likelihoods for smoothing fundi:
                # ------------------------------------------------------------
                LikelihoodNode = Node(name='Likelihood',
                    interface=Fn(function=compute_likelihood,
                                 input_names=['trained_file',
                                              'depth_file',
                                              'curvature_file',
                                              'folds',
                                              'save_file'],
                                 output_names=['likelihoods',
                                               'likelihoods_file']))
                SurfFeatureFlow.add_nodes([LikelihoodNode])
                border_params_file = \
                    'depth_curv_border_nonborder_parameters.pkl'
                border_params_path = fetch_check_data(border_params_file, url,
                                                   hashes, cache_env, cache)
                LikelihoodNode.inputs.trained_file = border_params_path
                mbFlow.connect([(WholeSurfShapeFlow, SurfFeatureFlow,
                    [('Rescale_travel_depth.rescaled_scalars_file',
                      'Likelihood.depth_file'),
                     ('Curvature.mean_curvature_file',
                      'Likelihood.curvature_file')])])
                SurfFeatureFlow.connect(FoldsNode, 'folds',
                                        LikelihoodNode, 'folds')
                LikelihoodNode.inputs.save_file = True
                # ------------------------------------------------------------
                # Smooth fundi:
                # ------------------------------------------------------------
                SmoothFundi = Node(name='Smooth_fundi',
                                   interface=Fn(function=smooth_skeleton,
                                        input_names=['skeletons',
                                                     'bounds',
                                                     'vtk_file',
                                                     'likelihoods',
                                                     'wN_max',
                                                     'erode_again',
                                                     'save_file'],
                                        output_names=['smooth_skeletons',
                                                      'n_skeletons',
                                                      'skeletons_file']))
                SurfFeatureFlow.connect(FundusPerFold, 'fundus_per_fold',
                                        SmoothFundi, 'skeletons')
                SurfFeatureFlow.connect(FoldsNode, 'folds',
                                        SmoothFundi, 'bounds')
                mbFlow.connect(WholeSurfShapeFlow,
                               'Curvature.mean_curvature_file',
                               SurfFeatureFlow, 'Smooth_fundi.vtk_file')
                SurfFeatureFlow.connect(LikelihoodNode, 'likelihoods',
                                        SmoothFundi, 'likelihoods')
                SmoothFundi.inputs.wN_max = 1.0
                SmoothFundi.inputs.erode_again = False
                SmoothFundi.inputs.save_file = True
                if save_all:
                    mbFlow.connect(SurfFeatureFlow, 
                                   'Smooth_fundi.skeletons_file',
                                   Sink, 'features.@smooth_fundi')

            # ----------------------------------------------------------------
            # Segment a fundus per sulcus:
            # ----------------------------------------------------------------
            FundusPerSulcus = Node(name='Fundus_per_sulcus',
                               interface=Fn(function=segment_fundi,
                                    input_names=['fundus_per_fold',
                                                 'sulci',
                                                 'vtk_file',
                                                 'save_file',
                                                 'verbose'],
                                    output_names=['fundus_per_sulcus',
                                                  'n_fundi',
                                                  'fundus_per_sulcus_file']))
            if do_smooth_fundi:
                SurfFeatureFlow.connect(SmoothFundi, 'smooth_skeletons',
                                        FundusPerSulcus, 'fundus_per_fold')
            else:
                SurfFeatureFlow.connect(FundusPerFold, 'fundus_per_fold',
                                        FundusPerSulcus, 'fundus_per_fold')
            SurfFeatureFlow.connect(SulciNode, 'sulci', 
                                    FundusPerSulcus, 'sulci')
            mbFlow.connect(WholeSurfShapeFlow,
                           'Curvature.mean_curvature_file',
                           SurfFeatureFlow, 'Fundus_per_sulcus.vtk_file')
            FundusPerSulcus.inputs.save_file = True
            FundusPerSulcus.inputs.verbose = True
            if save_all:
                mbFlow.connect(SurfFeatureFlow,
                               'Fundus_per_sulcus.fundus_per_sulcus_file',
                               Sink, 'features.@fundus_per_sulcus')

    # ========================================================================
    #
    #   Surface feature shapes
    #
    # ========================================================================
    if do_shapes:
        SurfFeatureShapeFlow = Workflow(name='Surface_feature_shapes')
        # ====================================================================
        # Compute Laplace-Beltrami spectra
        # ====================================================================
        if do_spectra:
            # ----------------------------------------------------------------
            # Measure spectra of labeled regions:
            # ----------------------------------------------------------------
            SpectraLabels = Node(name='Spectra_labels',
                                 interface=Fn(function=spectrum_per_label,
                                              input_names=['vtk_file',
                                                           'spectrum_size',
                                                           'exclude_labels',
                                                           'normalization',
                                                           'area_file',
                                                           'largest_segment'],
                                              output_names=['spectrum_lists',
                                                            'label_list']))
            SurfFeatureShapeFlow.add_nodes([SpectraLabels])
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           SurfFeatureShapeFlow, 'Spectra_labels.vtk_file')
            SpectraLabels.inputs.spectrum_size = spectra
            SpectraLabels.inputs.exclude_labels = [0]
            SpectraLabels.inputs.normalization = "area"
            SpectraLabels.inputs.area_file = ""
            SpectraLabels.inputs.largest_segment = True
            mbFlow.connect(WholeSurfShapeFlow, 'Surface_area.area_file',
                           SurfFeatureShapeFlow, 'Spectra_labels.area_file')
            # ----------------------------------------------------------------
            # Compute spectra of sulci:
            # ----------------------------------------------------------------
            if do_sulci:
                SpectraSulci = SpectraLabels.clone('Spectra_sulci')
                SurfFeatureShapeFlow.add_nodes([SpectraSulci])
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci_file',
                               SurfFeatureShapeFlow, 'Spectra_sulci.vtk_file')
                SpectraSulci.inputs.exclude_labels = [-1]

        # ====================================================================
        # Compute Zernike moments
        # ====================================================================
        if do_moments:
            # ----------------------------------------------------------------
            # Measure Zernike moments of labeled regions:
            # ----------------------------------------------------------------
            ZernikeLabels = Node(name='Zernike_labels',
                 interface=Fn(function=zernike_moments_per_label,
                              input_names=['vtk_file',
                                           'order',
                                           'exclude_labels',
                                           'scale_input',
                                           'decimate_fraction',
                                           'decimate_smooth'],
                              output_names=['descriptors_lists',
                                            'label_list']))
            SurfFeatureShapeFlow.add_nodes([ZernikeLabels])
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           SurfFeatureShapeFlow, 'Zernike_labels.vtk_file')
            ZernikeLabels.inputs.order = moments
            ZernikeLabels.inputs.exclude_labels = [0]
            ZernikeLabels.inputs.scale_input = True
            ZernikeLabels.inputs.decimate_fraction = 0
            ZernikeLabels.inputs.decimate_smooth = 0
            # ----------------------------------------------------------------
            # Compute Zernike moments of sulci:
            # ----------------------------------------------------------------
            if do_sulci:
                ZernikeSulci = ZernikeLabels.clone('Zernike_sulci')
                SurfFeatureShapeFlow.add_nodes([ZernikeSulci])
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci_file',
                               SurfFeatureShapeFlow, 'Zernike_sulci.vtk_file')
                ZernikeSulci.inputs.exclude_labels = [-1]

    # ========================================================================
    #
    #   Surface feature shape tables
    #
    # ========================================================================
    if do_shapes:
        # --------------------------------------------------------------------
        # Surface feature shape tables: labels, sulci, fundi:
        # --------------------------------------------------------------------
        ShapeTables = Node(name='Shape_tables',
                           interface=Fn(function=write_shape_stats,
                                input_names=['labels_or_file',
                                             'sulci',
                                             'fundi',
                                             'affine_transform_files',
                                             'inverse_booleans',
                                             'transform_format',
                                             'area_file',
                                             'normalize_by_area',
                                             'mean_curvature_file',
                                             'travel_depth_file',
                                             'geodesic_depth_file',
                                             'freesurfer_thickness_file',
                                             'freesurfer_curvature_file',
                                             'freesurfer_sulc_file',
                                             'labels_spectra',
                                             'labels_spectra_IDs',
                                             'sulci_spectra',
                                             'sulci_spectra_IDs',
                                             'labels_zernike',
                                             'labels_zernike_IDs',
                                             'sulci_zernike',
                                             'sulci_zernike_IDs',
                                             'exclude_labels'],
                                output_names=['label_table',
                                              'sulcus_table',
                                              'fundus_table']))
        mbFlow.add_nodes([ShapeTables])
        ShapeTables.inputs.labels_or_file = []
        ShapeTables.inputs.sulci = []
        ShapeTables.inputs.fundi = []
        ShapeTables.inputs.affine_transform_files = None
        ShapeTables.inputs.inverse_booleans = None
        ShapeTables.inputs.transform_format = None
        ShapeTables.inputs.freesurfer_thickness_file = ''
        ShapeTables.inputs.freesurfer_curvature_file = ''
        ShapeTables.inputs.freesurfer_sulc_file = ''
        ShapeTables.inputs.labels_spectra = []
        ShapeTables.inputs.sulci_spectra = []
        ShapeTables.inputs.labels_spectra_IDs = []
        ShapeTables.inputs.sulci_spectra_IDs = []
        ShapeTables.inputs.labels_zernike = []
        ShapeTables.inputs.sulci_zernike = []
        ShapeTables.inputs.labels_zernike_IDs = []
        ShapeTables.inputs.sulci_zernike_IDs = []
        if do_label:
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           ShapeTables, 'labels_or_file')
        if do_sulci:
            mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci',
                           ShapeTables, 'sulci')
        if do_fundi:
            mbFlow.connect(SurfFeatureFlow,
                           'Fundus_per_sulcus.fundus_per_sulcus',
                           ShapeTables, 'fundi')
        if use_ants:
            mbFlow.connect(ListSubject2mniAffineTransforms, 'string_list',
                           ShapeTables, 'affine_transform_files')
            ShapeTables.inputs.inverse_booleans = inverse_Booleans
            ShapeTables.inputs.transform_format = 'itk'
        ShapeTables.inputs.normalize_by_area = False
        mbFlow.connect([(WholeSurfShapeFlow, ShapeTables,
                   [('Surface_area.area_file', 'area_file'),
                    ('Curvature.mean_curvature_file', 'mean_curvature_file'),
                    ('Travel_depth.depth_file', 'travel_depth_file'),
                    ('Geodesic_depth.depth_file', 'geodesic_depth_file')])])
        if do_freesurfer_thickness:
            mbFlow.connect(WholeSurfShapeFlow, 
                           'Freesurfer_thickness_to_vtk.output_vtk',
                           ShapeTables, 'freesurfer_thickness_file')
        if do_freesurfer_curvature:
            mbFlow.connect(WholeSurfShapeFlow, 
                           'Freesurfer_curv_to_vtk.output_vtk',
                           ShapeTables, 'freesurfer_curvature_file')
        if do_freesurfer_sulc:
            mbFlow.connect(WholeSurfShapeFlow, 
                           'Freesurfer_sulc_to_vtk.output_vtk',
                           ShapeTables, 'freesurfer_sulc_file')

        # Laplace-Beltrami spectra:
        if do_spectra:
            mbFlow.connect(SurfFeatureShapeFlow,
                           'Spectra_labels.spectrum_lists',
                           ShapeTables, 'labels_spectra')
            mbFlow.connect(SurfFeatureShapeFlow, 'Spectra_labels.label_list',
                           ShapeTables, 'labels_spectra_IDs')
            if do_sulci:
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Spectra_sulci.spectrum_lists',
                               ShapeTables, 'sulci_spectra')
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Spectra_sulci.label_list',
                               ShapeTables, 'sulci_spectra_IDs')
            else:
                ShapeTables.inputs.sulci_spectra = []
                ShapeTables.inputs.sulci_spectra_IDs = []

        # Zernike moments:
        if do_moments:
            mbFlow.connect(SurfFeatureShapeFlow,
                           'Zernike_labels.descriptors_lists',
                           ShapeTables, 'labels_zernike')
            mbFlow.connect(SurfFeatureShapeFlow, 'Zernike_labels.label_list',
                           ShapeTables, 'labels_zernike_IDs')
            if do_sulci:
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Zernike_sulci.descriptors_lists',
                               ShapeTables, 'sulci_zernike')
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Zernike_sulci.label_list',
                               ShapeTables, 'sulci_zernike_IDs')
            else:
                ShapeTables.inputs.sulci_zernike = []
                ShapeTables.inputs.sulci_zernike_IDs = []

        ShapeTables.inputs.exclude_labels = [-1]
        mbFlow.connect(ShapeTables, 'label_table', Sink, 'tables.@labels')
        if do_sulci:
            mbFlow.connect(ShapeTables, 'sulcus_table', Sink, 'tables.@sulci')
        if do_fundi:
            mbFlow.connect(ShapeTables, 'fundus_table', Sink, 'tables.@fundi')
        # --------------------------------------------------------------------
        # Vertex measures table:
        # --------------------------------------------------------------------
        if do_points:
            VertexTable = Node(name='Vertex_table',
                               interface=Fn(function=write_vertex_measures,
                                    input_names=['output_table',
                                                 'labels_or_file',
                                                 'sulci',
                                                 'fundi',
                                                 'affine_transform_files',
                                                 'inverse_booleans',
                                                 'transform_format',
                                                 'area_file',
                                                 'mean_curvature_file',
                                                 'travel_depth_file',
                                                 'geodesic_depth_file',
                                                 'freesurfer_thickness_file',
                                                 'freesurfer_curvature_file',
                                                 'freesurfer_sulc_file'],
                                    output_names=['output_table']))
            mbFlow.add_nodes([VertexTable])
            VertexTable.inputs.output_table = ''
            VertexTable.inputs.labels_or_file = []
            VertexTable.inputs.sulci = []
            VertexTable.inputs.fundi = []
            VertexTable.inputs.affine_transform_files = None
            VertexTable.inputs.inverse_booleans = None
            VertexTable.inputs.transform_format = None
            VertexTable.inputs.freesurfer_thickness_file = ''
            VertexTable.inputs.freesurfer_curvature_file = ''
            VertexTable.inputs.freesurfer_sulc_file = ''
            if do_label:
                mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                               VertexTable, 'labels_or_file')
            if do_sulci:
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci',
                               VertexTable, 'sulci')
            if do_fundi:
                mbFlow.connect(SurfFeatureFlow,
                               'Fundus_per_sulcus.fundus_per_sulcus',
                               VertexTable, 'fundi')

            if use_ants:
                mbFlow.connect(ListSubject2mniAffineTransforms, 'string_list',
                               VertexTable, 'affine_transform_files')
                VertexTable.inputs.inverse_booleans = inverse_Booleans
                VertexTable.inputs.transform_format = 'itk'
            mbFlow.connect([(WholeSurfShapeFlow, VertexTable,
                               [('Surface_area.area_file','area_file'),
                                ('Travel_depth.depth_file',
                                 'travel_depth_file'),
                                ('Geodesic_depth.depth_file',
                                 'geodesic_depth_file'),
                                ('Curvature.mean_curvature_file',
                                 'mean_curvature_file')])])
            if do_freesurfer_thickness:
                mbFlow.connect(WholeSurfShapeFlow,
                               'Freesurfer_thickness_to_vtk.output_vtk',
                               VertexTable, 'freesurfer_thickness_file')
            if do_freesurfer_curvature:
                mbFlow.connect(WholeSurfShapeFlow,
                               'Freesurfer_curv_to_vtk.output_vtk',
                               VertexTable, 'freesurfer_curvature_file')
            if do_freesurfer_sulc:
                mbFlow.connect(WholeSurfShapeFlow,
                               'Freesurfer_sulc_to_vtk.output_vtk',
                               VertexTable, 'freesurfer_sulc_file')
            mbFlow.connect(VertexTable, 'output_table',
                           Sink, 'tables.@vertices')

        # --------------------------------------------------------------------
        # Apply affine transform to surface coordinates:
        # --------------------------------------------------------------------
        if use_ants and do_surfaces_in_mni:
            TransformPoints = Node(name='Transform_surface_points',
                                interface=Fn(function=apply_affine_transforms,
                                             input_names=['transform_files',
                                                          'inverse_booleans',
                                                          'transform_format',
                                                          'vtk_or_points',
                                                          'vtk_file_stem'],
                                             output_names=['affine_points',
                                                           'output_file']))
            mbFlow.add_nodes([TransformPoints])
            mbFlow.connect(ListSubject2mniAffineTransforms, 'string_list',
                           TransformPoints, 'transform_files')
            mbFlow.connect(TravelDepth, 'depth_file',
                           TransformPoints, 'vtk_or_points')
            TransformPoints.inputs.inverse_booleans = inverse_Booleans
            TransformPoints.inputs.transform_format = 'itk'
            TransformPoints.inputs.vtk_file_stem = 'affine_'
            if save_all:
                mbFlow.connect(TransformPoints, 'output_file',
                               Sink, 'features.@surface_in_MNI152')


# ============================================================================
# ----------------------------------------------------------------------------
#
#   Volume workflows
#
# ----------------------------------------------------------------------------
# ============================================================================
if do_label and not args.no_volumes:

    # ========================================================================
    #
    #   Location and structure of FreeSurfer volume inputs
    #
    # ========================================================================
    # ------------------------------------------------------------------------
    # Original image (.mgz) for converting from conformal (below):
    # ------------------------------------------------------------------------
    MRImgh = Node(name='MRI_mgh_format',
                  interface=DataGrabber(infields=['subject'],
                                        outfields=['MRI_mgh_format'],
                                        sort_filelist=False))
    MRImgh.inputs.base_directory = subjects_dir
    second_scan = os.path.join(subjects_dir, 'mri/orig/002.mgz')
    if os.path.exists(second_scan):
        raise IOError("Mindboggle can not make use of FreeSurfer "
                      "output with more than one scan: " + second_scan)
    MRImgh.inputs.template = '%s/mri/orig/001.mgz'
    MRImgh.inputs.template_args['MRI_mgh_format'] = [['subject']]
    MRImgh.inputs.subject = subject
    # --------------------------------------------------------------------
    # Convert FreeSurfer mgh conformal file to nifti format:
    # --------------------------------------------------------------------
    mgh2nifti = Node(name='Convert_MRI_to_nifti_format',
                     interface=Fn(function=convert2nii,
                                  input_names=['input_file',
                                               'reference_file',
                                               'output_file',
                                               'interp'],
                                  output_names=['output_file']))
    mbFlow.connect(MRImgh, 'MRI_mgh_format', mgh2nifti, 'input_file')
    mbFlow.connect(MRImgh, 'MRI_mgh_format', mgh2nifti, 'reference_file')
    mgh2nifti.inputs.output_file = ''
    mgh2nifti.inputs.interp = 'continuous'
    # ------------------------------------------------------------------------
    # Use own whole-brain nifti label volume:
    # ------------------------------------------------------------------------
    if do_input_fs_labels:
        labels2nifti = Node(name='Labels_nifti_format',
                            interface=DataGrabber(infields=['subject'],
                                                  outfields=['labels'],
                                                  sort_filelist=False))
        labels2nifti.inputs.base_directory = subjects_dir
        labels2nifti.inputs.template = '%s/mri/' + volume_labels+'.nii.gz'
        labels2nifti.inputs.template_args['labels'] = [['subject']]
        labels2nifti.inputs.subject = subject
    # ------------------------------------------------------------------------
    # Convert FreeSurfer whole-brain label volume to nifti format:
    # ------------------------------------------------------------------------
    else:
        # --------------------------------------------------------------------
        #  label volume:
        # --------------------------------------------------------------------
        labels2mgh = Node(name='Labels_mgh_format',
                          interface=DataGrabber(infields=['subject'],
                                                outfields=['labels'],
                                                sort_filelist=False))
        labels2mgh.inputs.base_directory = subjects_dir
        labels2mgh.inputs.template = '%s/mri/' + volume_labels+'.mgz'
        labels2mgh.inputs.template_args['labels'] = [['subject']]
        labels2mgh.inputs.subject = subject
        # --------------------------------------------------------------------
        # Convert FreeSurfer mgh conformal file to nifti format:
        # --------------------------------------------------------------------
        labelsmgh2nifti = Node(name='Convert_labels_to_nifti_format',
                               interface=Fn(function=convert2nii,
                                            input_names=['input_file',
                                                         'reference_file',
                                                         'output_file',
                                                         'interp'],
                                            output_names=['output_file']))
        mbFlow.connect(labels2mgh, 'labels', labelsmgh2nifti, 'input_file')
        mbFlow.connect(MRImgh, 'MRI_mgh_format',
                       labelsmgh2nifti, 'reference_file')
        labelsmgh2nifti.inputs.output_file = ''
        labelsmgh2nifti.inputs.interp = 'nearest'
        #if save_all:
        #    mbFlow.connect(labelsmgh2nifti, 'output_file',
        #                   Sink, 'labels.@freesurfer')

    # ========================================================================
    #
    #   Volume labels
    #
    # ========================================================================
    VolLabelFlow = Workflow(name='Volume_labels')

    # ------------------------------------------------------------------------
    # Extract FreeSurfer cerebellum labels:
    # ------------------------------------------------------------------------
    FScerebellum = Node(name='Extract_freesurfer_cerebella',
                        interface=Fn(function=keep_volume_labels,
                                     input_names=['input_file',
                                                  'labels_to_keep',
                                                  'output_file',
                                                  'second_file'],
                                     output_names=['output_file']))
    VolLabelFlow.add_nodes([FScerebellum])
    if do_input_fs_labels:
        mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                       'Extract_freesurfer_cerebella.input_file')
    else:
        mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                       'Extract_freesurfer_cerebella.input_file')
    FScerebellum.inputs.labels_to_keep = dkt.cerebellum_numbers
    FScerebellum.inputs.output_file = ''
    FScerebellum.inputs.second_file = ''

    # ========================================================================
    # Combine FreeSurfer and ANTs cerebrum gray/white matter volumes
    # ========================================================================
    if not my_graywhite:
        # --------------------------------------------------------------------
        # Extract FreeSurfer cerebrum labels:
        # --------------------------------------------------------------------
        FScerebrum = Node(name='Extract_freesurfer_cerebra',
                          interface=Fn(function=keep_volume_labels,
                                       input_names=['input_file',
                                                    'labels_to_keep',
                                                    'output_file',
                                                    'second_file'],
                                       output_names=['output_file']))
        VolLabelFlow.add_nodes([FScerebrum])
        if do_input_fs_labels:
            mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                           'Extract_freesurfer_cerebra.input_file')
        else:
            mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                           'Extract_freesurfer_cerebra.input_file')
        labels_to_segment = dkt.cerebrum_cortex_numbers + \
                            dkt.cerebrum_noncortex_numbers + \
                            dkt.brainstem_numbers + \
                            dkt.extra_numbers
        FScerebrum.inputs.labels_to_keep = labels_to_segment
        FScerebrum.inputs.output_file = ''
        FScerebrum.inputs.second_file = ''
        # --------------------------------------------------------------------
        # Convert FreeSurfer cerebrum labels to non/cortex segments:
        # --------------------------------------------------------------------
        FSgraywhite = Node(name='Freesurfer_cerebrum_labels_to_graywhite',
                           interface=Fn(function=relabel_volume,
                                        input_names=['input_file',
                                                     'old_labels',
                                                     'new_labels',
                                                     'output_file'],
                                        output_names=['output_file']))
        VolLabelFlow.add_nodes([FSgraywhite])
        VolLabelFlow.connect(FScerebrum, 'output_file',
                             FSgraywhite, 'input_file')
        FSgraywhite.inputs.old_labels = labels_to_segment
        FSgraywhite.inputs.new_labels = \
            [2 for x in dkt.cerebrum_cortex_numbers] + \
            [3 for x in dkt.cerebrum_noncortex_numbers] + \
            [3 for x in dkt.brainstem_numbers] + \
            [3 for x in dkt.extra_numbers]
        FSgraywhite.inputs.output_file = ''
        # --------------------------------------------------------------------
        # Convert ANTs Atropos-segmented volume to non/cortex segments:
        # --------------------------------------------------------------------
        if use_ants:
            antsGrayWhite = FSgraywhite.clone('Ants_brain_labels_to_graywhite')
            VolLabelFlow.add_nodes([antsGrayWhite])
            mbFlow.connect(FetchAnts, 'segments', VolLabelFlow,
                           'Ants_brain_labels_to_graywhite.input_file')
            antsGrayWhite.inputs.old_labels = [1, 4]
            antsGrayWhite.inputs.new_labels = [0, 3]
            antsGrayWhite.inputs.output_file = ''
            # ----------------------------------------------------------------
            # Combine FreeSurfer and ANTs cerebrum segmentation volumes to
            # obtain a single cortex (2) and noncortex (3) segmentation file:
            # ----------------------------------------------------------------
            JoinGrayWhite = Node(name=
                            'Combine_freesurfer_ants_cerebrum_graywhite',
                            interface=Fn(function=combine_2labels_in_2volumes,
                                         input_names=['file1',
                                                      'file2',
                                                      'label1',
                                                      'label2',
                                                      'output_file'],
                                         output_names=['output_file']))
            VolLabelFlow.add_nodes([JoinGrayWhite])
            VolLabelFlow.connect(FSgraywhite, 'output_file', 
                                 JoinGrayWhite, 'file1')
            JoinGrayWhite.inputs.out_dir = ''
            VolLabelFlow.connect(antsGrayWhite, 'output_file',
                                 JoinGrayWhite, 'file2')
            JoinGrayWhite.inputs.label1 = 3
            JoinGrayWhite.inputs.label2 = 2
            JoinGrayWhite.inputs.output_file = ''
            # ----------------------------------------------------------------
            # Erase cerebrum that overlaps with FreeSurfer cerebellum:
            # ----------------------------------------------------------------
            if overwrite_cerebrum_with_cerebellum:
                RemoveCerebellum = Node(
                    name='Remove_cerebrum_cerebellum_overlap',
                    interface=Fn(function=remove_volume_labels,
                                 input_names=['input_file',
                                              'labels_to_remove',
                                              'output_file',
                                              'second_file'],
                                 output_names=['output_file']))
                VolLabelFlow.add_nodes([RemoveCerebellum])
                VolLabelFlow.connect(FScerebellum, 'output_file',
                                     RemoveCerebellum, 'input_file')
                RemoveCerebellum.inputs.labels_to_remove = \
                    dkt.cerebellum_numbers
                RemoveCerebellum.inputs.output_file = ''
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     RemoveCerebellum, 'second_file')

    # ========================================================================
    # Split segmented brain into two sides (without medial regions)
    # ========================================================================
    # if modify_surface_labels:
    #     # --------------------------------------------------------------------
    #     # Split brain by masking with left or right labels:
    #     # --------------------------------------------------------------------
    #     SplitBrain = Node(name='Split_brain',
    #                           interface=Fn(function=split_brain,
    #                                        input_names=['image_file',
    #                                                     'label_file',
    #                                                     'left_labels',
    #                                                     'right_labels'],
    #                                        output_names=['left_brain',
    #                                                      'right_brain']))
    #     VolLabelFlow.add_nodes([SplitBrain])
    #     if my_graywhite:
    #         SplitBrain.inputs.image_file = my_graywhite
    #     else:
    #         if use_ants:
    #             if overwrite_cerebrum_with_cerebellum:
    #                 VolLabelFlow.connect(RemoveCerebellum, 'output_file',
    #                                      SplitBrain, 'image_file')
    #             else:
    #                 VolLabelFlow.connect(JoinGrayWhite, 'output_file',
    #                                      SplitBrain, 'image_file')
    #         else:
    #             VolLabelFlow.connect(FSgraywhite, 'output_file',
    #                                  SplitBrain, 'image_file')
    #     if do_input_fs_labels:
    #         mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
    #                        'Split_brain.label_file')
    #     else:
    #         mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
    #                        'Split_brain.label_file')
    #     SplitBrain.inputs.left_labels = dkt.left_cerebrum_numbers
    #     SplitBrain.inputs.right_labels = dkt.right_cerebrum_numbers

    # ========================================================================
    # Fill cerebrum segmentation volumes with FreeSurfer labels
    # ========================================================================
    # ------------------------------------------------------------------------
    # Extract cerebrum noncortical volume labels:
    # ------------------------------------------------------------------------
    FSnoncortex = Node(name='Extract_freesurfer_noncortex_labels',
                       interface=Fn(function=keep_volume_labels,
                                    input_names=['input_file',
                                                 'labels_to_keep',
                                                 'output_file',
                                                 'second_file'],
                                    output_names=['output_file']))
    VolLabelFlow.add_nodes([FSnoncortex])
    if do_input_fs_labels:
        mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                       'Extract_freesurfer_noncortex_labels.input_file')
    else:
        mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                       'Extract_freesurfer_noncortex_labels.input_file')
    labels_to_fill = dkt.cerebrum_noncortex_numbers + \
                     dkt.brainstem_numbers + \
                     dkt.extra_numbers
    FSnoncortex.inputs.labels_to_keep = labels_to_fill
    FSnoncortex.inputs.output_file = ''
    FSnoncortex.inputs.second_file = ''
    # ------------------------------------------------------------------------
    # Propagate FreeSurfer volume labels through noncortex:
    # ------------------------------------------------------------------------
    FillFSnoncortex = Node(name='Fill_noncortex_with_freesurfer_labels',
                           interface=Fn(function=PropagateLabelsThroughMask,
                                        input_names=['mask',
                                                     'labels',
                                                     'mask_index',
                                                     'output_file',
                                                     'binarize',
                                                     'stopvalue'],
                                        output_names=['output_file']))
    VolLabelFlow.add_nodes([FillFSnoncortex])
    if my_graywhite:
        FillFSnoncortex.inputs.mask = my_graywhite
    else:
        if use_ants:
            if overwrite_cerebrum_with_cerebellum:
                VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                     FillFSnoncortex, 'mask')
            else:
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     FillFSnoncortex, 'mask')
        else:
            VolLabelFlow.connect(FSgraywhite, 'output_file',
                                 FillFSnoncortex, 'mask')
    VolLabelFlow.connect(FSnoncortex, 'output_file',
                         FillFSnoncortex, 'labels')
    FillFSnoncortex.inputs.mask_index = 3
    FillFSnoncortex.inputs.output_file = ''
    FillFSnoncortex.inputs.binarize = False
    FillFSnoncortex.inputs.stopvalue = ''
    # ------------------------------------------------------------------------
    # Propagate FreeSurfer surface labels through whole-brain cortex:
    # ------------------------------------------------------------------------
    # if modify_surface_labels:
    #
    #     print('NOTE: Evaluate surface-to-volume label propagation'
    #           ' when surface label modification algorithm complete.')
    #
    #     # --------------------------------------------------------------------
    #     # Propagate surface labels through each hemisphere's cortex:
    #     # --------------------------------------------------------------------
    #     FillcortexFSsurf = Node(
    #                 name='Fill_cortex_with_freesurfer_surface_labels',
    #                 interface=Fn(function=fill_volume_with_surface_labels,
    #                              input_names=['hemi',
    #                                           'left_mask',
    #                                           'right_mask',
    #                                           'surface_files',
    #                                           'mask_index',
    #                                           'output_file',
    #                                           'binarize'],
    #                              output_names=['output_file']))
    #     VolLabelFlow.add_nodes([FillcortexFSsurf])
    #     mbFlow.connect(InputHemis, 'hemi', VolLabelFlow,
    #                    'Fill_cortex_with_freesurfer_surface_labels.hemi')
    #     VolLabelFlow.connect(SplitBrain, 'left_brain',
    #                          FillcortexFSsurf, 'left_mask')
    #     VolLabelFlow.connect(SplitBrain, 'right_brain',
    #                          FillcortexFSsurf, 'right_mask')
    #     mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
    #         VolLabelFlow,
    #         'Fill_cortex_with_freesurfer_surface_labels.surface_files')
    #     FillcortexFSsurf.inputs.mask_index = 2
    #     FillcortexFSsurf.inputs.output_file = ''
    #     FillcortexFSsurf.inputs.binarize = False
    #     # --------------------------------------------------------------------
    #     # Combine left and right cortical labels:
    #     # --------------------------------------------------------------------
    #     SplitHemiList = JoinNode(name='Split_hemisphere_list',
    #                              interface=Fn(function=split_list_pair,
    #                                           input_names=['List'],
    #                                           output_names=['element1',
    #                                                         'element2']),
    #                              joinsource="Input_hemispheres",
    #                              joinfield="List")
    #     LRcortex = Node(name='Combine_left_right_cortex_labels',
    #                     interface=Fn(function=ImageMath,
    #                                  input_names=['volume1',
    #                                               'volume2',
    #                                               'operator',
    #                                               'output_file'],
    #                                  output_names=['output_file']))
    #     VolLabelFlow.add_nodes([SplitHemiList, LRcortex])
    #     VolLabelFlow.connect(FillcortexFSsurf, 'output_file',
    #                          SplitHemiList, 'List')
    #     VolLabelFlow.connect(SplitHemiList, 'element1', LRcortex, 'volume1')
    #     VolLabelFlow.connect(SplitHemiList, 'element2', LRcortex, 'volume2')
    #     LRcortex.inputs.operator = '+'
    #     LRcortex.inputs.output_file = ''
    #else:
    # ------------------------------------------------------------------------
    # Propagate FreeSurfer volume labels through whole-brain cortex:
    # ------------------------------------------------------------------------
    # Extract FreeSurfer cerebrum cortical volume labels:
    FScortex = FSnoncortex.clone('Extract_freesurfer_cortex_labels')
    VolLabelFlow.add_nodes([FScortex])
    if do_input_fs_labels:
        mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                       'Extract_freesurfer_cortex_labels.input_file')
    else:
        mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                       'Extract_freesurfer_cortex_labels.input_file')
    FScortex.inputs.labels_to_keep = dkt.cerebrum_cortex_numbers
    FScortex.inputs.output_file = ''
    FScortex.inputs.second_file = ''

    # Propagate volume labels through whole-brain cortex:
    FillFScortex = FillFSnoncortex.clone('Fill_cortex_with_freesurfer_labels')
    VolLabelFlow.add_nodes([FillFScortex])
    if my_graywhite:
        FillFScortex.inputs.mask = my_graywhite
    else:
        if use_ants:
            if overwrite_cerebrum_with_cerebellum:
                VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                     FillFScortex, 'mask')
            else:
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     FillFScortex, 'mask')
        else:
            VolLabelFlow.connect(FSgraywhite, 'output_file',
                                 FillFScortex, 'mask')
    VolLabelFlow.connect(FScortex, 'output_file',
                         FillFScortex, 'labels')
    FillFScortex.inputs.mask_index = 2
    # ------------------------------------------------------------------------
    # Combine FreeSurfer label-filled whole-brain cortex and noncortex:
    # ------------------------------------------------------------------------
    CombineFSLabels = Node(name=
                           'Combine_freesurfer_cortex_noncortex_labels',
                           interface=Fn(function=overwrite_volume_labels,
                                        input_names=['source',
                                                     'target',
                                                     'output_file',
                                                     'ignore_labels',
                                                     'erase_labels'],
                                        output_names=['output_file']))
    VolLabelFlow.add_nodes([CombineFSLabels])
    VolLabelFlow.connect(FillFSnoncortex, 'output_file',
                         CombineFSLabels, 'source')
    #if modify_surface_labels:
    #    VolLabelFlow.connect(LRcortex, 'output_file',
    #                         CombineFSLabels, 'target')
    #else:
    VolLabelFlow.connect(FillFScortex, 'output_file',
                         CombineFSLabels, 'target')
    CombineFSLabels.inputs.output_file = ''
    CombineFSLabels.inputs.ignore_labels = [0]
    CombineFSLabels.inputs.erase_labels = False
    if save_all and not overwrite_cerebrum_with_cerebellum:
        mbFlow.connect(VolLabelFlow,
               'Combine_freesurfer_cortex_noncortex_labels.output_file',
               Sink, 'labels.@freesurfer_filled')

    # ========================================================================
    # Fill whole-brain segmentation volumes with ANTs labels
    # ========================================================================
    if use_ants:
        # --------------------------------------------------------------------
        # Mask brain volume:
        # --------------------------------------------------------------------
        #MaskBrain = Node(name= 'Mask_brain',
        #                 interface=Fn(function=ImageMath,
        #                              input_names=['volume1',
        #                                           'volume2',
        #                                           'operator',
        #                                           'output_file'],
        #                              output_names=['output_file']))
        #VolLabelFlow.add_nodes([MaskBrain])
        #mbFlow.connect(mgh2nifti, 'output_file',
        #               VolLabelFlow, 'Mask_brain.volume1')
        #mbFlow.connect(FetchAnts, 'mask', VolLabelFlow, 'Mask_brain.volume2')
        #MaskBrain.inputs.operator = 'm'
        #MaskBrain.inputs.output_file = ''
        # --------------------------------------------------------------------
        # Transform default atlas labels in MNI152 to subject via template:
        # --------------------------------------------------------------------
        xfm = Node(ApplyTransforms(), name='Apply_ants_transforms')
        VolLabelFlow.add_nodes([xfm])
        xfm.inputs.dimension = 3
        xfm.inputs.default_value = 0
        xfm.inputs.interpolation = 'NearestNeighbor'
        xfm.inputs.invert_transform_flags = warp_inverse_Booleans
        xfm.inputs.output_image = 'ants_labels.nii.gz'
        if my_graywhite:
            xfm.inputs.reference_image = my_graywhite
        else:
            mbFlow.connect(FetchAnts, 'segments', VolLabelFlow,
                           'Apply_ants_transforms.reference_image')
        if my_atlas:
            xfm.inputs.input_image = my_atlas
        else:
            mbFlow.connect(FetchAtlas, 'data_path',
                           VolLabelFlow, 'Apply_ants_transforms.input_image')

        mbFlow.connect(ListSubject2mniTransforms, 'string_list', VolLabelFlow,
                       'Apply_ants_transforms.transforms')
        #if save_all:
        #    mbFlow.connect(VolLabelFlow, 'Apply_ants_transforms.output_image',
        #                   Sink, 'labels.@antsRegistration')
        # --------------------------------------------------------------------
        # Extract ANTs cerebral cortical volume labels:
        # --------------------------------------------------------------------
        antsCortex = FSnoncortex.clone('Extract_ants_cortex_labels')
        VolLabelFlow.add_nodes([antsCortex])
        VolLabelFlow.connect(xfm, 'output_image', antsCortex, 'input_file')
        antsCortex.inputs.labels_to_keep = dkt.cerebrum_cortex_numbers
        antsCortex.inputs.output_file = ''
        antsCortex.inputs.second_file = ''
        # --------------------------------------------------------------------
        # Extract ANTs whole-brain noncortical volume labels:
        # --------------------------------------------------------------------
        antsNoncortex = antsCortex.clone('Extract_ants_noncortex_labels')
        VolLabelFlow.add_nodes([antsNoncortex])
        VolLabelFlow.connect(xfm, 'output_image', antsNoncortex, 'input_file')
        antsNoncortex.inputs.labels_to_keep = labels_to_fill
        antsNoncortex.inputs.output_file = ''
        # --------------------------------------------------------------------
        # Propagate ANTs whole-brain cortical volume labels through cortex:
        # --------------------------------------------------------------------
        FillAntsCortex = FillFSnoncortex.clone('Fill_cortex_with_ants_labels')
        VolLabelFlow.add_nodes([FillAntsCortex])
        if my_graywhite:
            FillAntsCortex.inputs.mask = my_graywhite
        else:
            if overwrite_cerebrum_with_cerebellum:
                VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                     FillAntsCortex, 'mask')
            else:
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     FillAntsCortex, 'mask')
        VolLabelFlow.connect(antsCortex, 'output_file',
                             FillAntsCortex, 'labels')
        FillAntsCortex.inputs.mask_index = 2
        FillAntsCortex.inputs.output_file = ''
        FillAntsCortex.inputs.binarize = False
        FillAntsCortex.inputs.stopvalue = ''
        # --------------------------------------------------------------------
        # Propagate ANTs whole-brain noncortical labels through noncortex:
        # --------------------------------------------------------------------
        if fill_noncortex_with_ants_labels:
            FillAntsNoncortex = FillAntsCortex.clone(
                'Fill_noncortex_with_ants_labels')
            VolLabelFlow.add_nodes([FillAntsNoncortex])
            if my_graywhite:
                FillAntsNoncortex.inputs.mask = my_graywhite
            else:
                if overwrite_cerebrum_with_cerebellum:
                    VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                         FillAntsNoncortex, 'mask')
                else:
                    VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                         FillAntsNoncortex, 'mask')
            VolLabelFlow.connect(antsNoncortex, 'output_file',
                                 FillAntsNoncortex, 'labels')
            FillAntsNoncortex.inputs.mask_index = 3
        # --------------------------------------------------------------------
        # Combine ANTs label-filled cortex and label-filled noncortex:
        # --------------------------------------------------------------------
        CombineAntsLabels = CombineFSLabels.clone(
            'Combine_ants_cortex_noncortex_labels')
        VolLabelFlow.add_nodes([CombineAntsLabels])
        if fill_noncortex_with_ants_labels:
            VolLabelFlow.connect(FillAntsNoncortex, 'output_file',
                                 CombineAntsLabels, 'source')
        else:
            VolLabelFlow.connect(antsNoncortex, 'output_file',
                                 CombineAntsLabels, 'source')
        VolLabelFlow.connect(FillAntsCortex, 'output_file',
                             CombineAntsLabels, 'target')
        CombineAntsLabels.inputs.output_file = ''
        CombineAntsLabels.inputs.ignore_labels = [0]
        CombineAntsLabels.inputs.erase_labels = False
        if save_all and not overwrite_cerebrum_with_cerebellum:
            mbFlow.connect(VolLabelFlow, 
                           'Combine_ants_cortex_noncortex_labels.output_file',
                           Sink, 'labels.@ants_filled')

    # ========================================================================
    # Add FreeSurfer cerebellum labels
    # ========================================================================
    if overwrite_cerebrum_with_cerebellum:
        # --------------------------------------------------------------------
        # ...to FreeSurfer cerebrum labels:
        # --------------------------------------------------------------------
        AddFScerebellum = CombineFSLabels.clone(
            'Add_freesurfer_cerebellum_to_cerebrum')
        VolLabelFlow.add_nodes([AddFScerebellum])
        VolLabelFlow.connect(FScerebellum, 'output_file',
                             AddFScerebellum, 'source')
        VolLabelFlow.connect(CombineFSLabels, 'output_file',
                             AddFScerebellum, 'target')
        AddFScerebellum.inputs.output_file = ''
        AddFScerebellum.inputs.ignore_labels = [0]
        AddFScerebellum.inputs.erase_labels = False
        if save_all:
            mbFlow.connect(VolLabelFlow,
                   'Add_freesurfer_cerebellum_to_cerebrum.output_file',
                    Sink, 'labels.@freesurfer_filled_and_cerebellum')
        # --------------------------------------------------------------------
        # ...to ANTs cerebrum labels:
        # --------------------------------------------------------------------
        if use_ants:
            AddFScerebellum2ANTs = AddFScerebellum.clone(
                'Add_freesurfer_cerebellum_to_ants_cerebrum')
            VolLabelFlow.add_nodes([AddFScerebellum2ANTs])
            VolLabelFlow.connect(FScerebellum, 'output_file',
                                 AddFScerebellum2ANTs, 'source')
            VolLabelFlow.connect(CombineAntsLabels, 'output_file',
                                 AddFScerebellum2ANTs, 'target')
            AddFScerebellum2ANTs.inputs.output_file = ''
            AddFScerebellum2ANTs.inputs.ignore_labels = [0]
            AddFScerebellum2ANTs.inputs.erase_labels = False
            if save_all:
                mbFlow.connect(VolLabelFlow,
                    'Add_freesurfer_cerebellum_to_ants_cerebrum.output_file',
                    Sink, 'labels.@ants_filled_and_cerebellum')

    # ========================================================================
    #
    # Transform labels from added atlas(es) in MNI152 to subject
    #
    # ========================================================================
    if add_atlas_names and use_ants:
        # --------------------------------------------------------------------
        # Find atlas path that contains atlas name:
        # --------------------------------------------------------------------
        MatchAtlas = Node(name='Match_added_atlas',
                      interface=Fn(function=first_string_containing_substring,
                                   input_names=['substring',
                                                'List'],
                                   output_names=['first_matching_string']))
        VolLabelFlow.add_nodes([MatchAtlas])
        mbFlow.connect(InputVolumeAtlases, 'atlas', VolLabelFlow,
                       'Match_added_atlas.substring')
        MatchAtlas.inputs.List = atlases
        # --------------------------------------------------------------------
        # Transform atlas:
        # --------------------------------------------------------------------
        xfm2 = xfm.clone('Transform_added_atlases')
        VolLabelFlow.add_nodes([xfm2])
        xfm2.inputs.output_image = 'ants_added_atlas_labels.nii.gz'
        VolLabelFlow.connect(MatchAtlas, 'first_matching_string',
                             xfm2, 'input_image')
        if my_graywhite:
            xfm2.inputs.reference_image = my_graywhite
        else:
            mbFlow.connect(FetchAnts, 'segments', VolLabelFlow,
                           'Transform_added_atlases.reference_image')
        mbFlow.connect(ListSubject2mniTransforms, 'string_list', VolLabelFlow,
                       'Transform_added_atlases.transforms')
        if save_all:
            mbFlow.connect(VolLabelFlow, 'Transform_added_atlases.output_image',
                           Sink, 'labels.@added_atlases')

    # ========================================================================
    #
    #   Volume feature shapes
    #
    # ========================================================================
    if do_shapes:

        VolShapeFlow = Workflow(name='Volume_feature_shapes')

        # ====================================================================
        # Measure volume of each region of a labeled image file
        # ====================================================================
        # --------------------------------------------------------------------
        # Volumes of the FreeSurfer labels filling gray/white matter:
        # --------------------------------------------------------------------
        VolumesFSlabels = Node(name='Volume_per_freesurfer_label',
                               interface=Fn(function=volume_per_brain_region,
                                            input_names=['input_file',
                                                         'include_labels',
                                                         'exclude_labels',
                                                         'label_names',
                                                         'save_table',
                                                         'output_table'],
                                            output_names=['unique_labels',
                                                          'volumes',
                                                          'output_table']))
        VolShapeFlow.add_nodes([VolumesFSlabels])
        VolumesFSlabels.inputs.include_labels = dkt.label_numbers
        VolumesFSlabels.inputs.exclude_labels = []
        VolumesFSlabels.inputs.label_names = dkt.label_names
        VolumesFSlabels.inputs.save_table = True
        VolumesFSlabels.inputs.output_table = \
            'volume_per_freesurfer_label.csv'
        mbFlow.connect(VolLabelFlow,
               'Combine_freesurfer_cortex_noncortex_labels.output_file',
               VolShapeFlow, 'Volume_per_freesurfer_label.input_file')
        mbFlow.connect(VolShapeFlow,
                       'Volume_per_freesurfer_label.output_table',
                       Sink, 'tables.@volumes_of_freesurfer_labels')
        if use_ants:
            # ----------------------------------------------------------------
            # Volumes of the ANTs labels filling gray/white matter:
            # ----------------------------------------------------------------
            VolumesAntsLabels = VolumesFSlabels.clone(
                'Volume_per_ants_label')
            VolShapeFlow.add_nodes([VolumesAntsLabels])
            VolumesAntsLabels.inputs.exclude_labels = [-1,0]
            VolumesAntsLabels.inputs.output_table = \
                'volume_per_ants_label.csv'
            if overwrite_cerebrum_with_cerebellum:
                mbFlow.connect(VolLabelFlow,
                   'Add_freesurfer_cerebellum_to_ants_cerebrum.output_file',
                   VolShapeFlow, 'Volume_per_ants_label.input_file')
            else:
                mbFlow.connect(VolLabelFlow,
                   'Combine_ants_cortex_noncortex_labels.output_file',
                   VolShapeFlow, 'Volume_per_ants_label.input_file')
            mbFlow.connect(VolShapeFlow,
                           'Volume_per_ants_label.output_table',
                           Sink, 'tables.@volumes_of_ants_labels')
            # ----------------------------------------------------------------
            # Volumes of labels in additional atlases transformed to subject:
            # ----------------------------------------------------------------
            if add_atlas_names:
                VolumesAntsLabels2 = VolumesFSlabels.clone(
                    'Volume_per_added_atlas_label')
                VolShapeFlow.add_nodes([VolumesAntsLabels2])
                VolumesAntsLabels2.inputs.label_names = []
                VolumesAntsLabels2.inputs.include_labels = dkt.label_numbers
                VolumesAntsLabels2.inputs.exclude_labels = [-1,0]
                VolumesAntsLabels2.inputs.output_table = \
                    'volume_per_added_label.csv'
                mbFlow.connect(VolLabelFlow,
                               'Transform_added_atlases.output_image',
                               VolShapeFlow,
                               'Volume_per_added_atlas_label.input_file')
                # Save table:
                mbFlow.connect(VolShapeFlow,
                               'Volume_per_added_atlas_label.output_table',
                               Sink, 'tables.@volumes_of_added_atlas_labels')

        # ====================================================================
        # Measure volume, thickness of cortical regions of labeled image file
        # ====================================================================
        if do_thickinthehead:
            # ----------------------------------------------------------------
            # Thicknesses of the FreeSurfer cortical labels:
            # ----------------------------------------------------------------
            FSthicknesses = Node(
                name='Thickness_per_freesurfer_cortex_label',
                interface=Fn(function=thickinthehead,
                             input_names=['segmented_file',
                                          'labeled_file',
                                          'cortex_value',
                                          'noncortex_value',
                                          'labels',
                                          'names',
                                          'resize',
                                          'propagate',
                                          'output_dir',
                                          'save_table',
                                          'output_table'],
                             output_names=['label_volume_thickness',
                                           'output_table']))
            VolShapeFlow.add_nodes([FSthicknesses])
            if my_graywhite:
                FSthicknesses.inputs.segmented_file = my_graywhite
            else:
                if use_ants:
                    if overwrite_cerebrum_with_cerebellum:
                        mbFlow.connect(VolLabelFlow,
                            'Remove_cerebrum_cerebellum_overlap.output_file',
                            VolShapeFlow,
                            'Thickness_per_freesurfer_cortex_label.'
                            'segmented_file')
                    else:
                        mbFlow.connect(VolLabelFlow,
                            'Combine_freesurfer_ants_cerebrum_graywhite.'
                            'output_file',
                            VolShapeFlow,
                            'Thickness_per_freesurfer_cortex_label.'
                            'segmented_file')
                else:
                    mbFlow.connect(VolLabelFlow,
                        'Freesurfer_cerebrum_labels_to_graywhite.output_file',
                        VolShapeFlow,
                        'Thickness_per_freesurfer_cortex_label.'
                        'segmented_file')
            mbFlow.connect(VolLabelFlow,
                'Combine_freesurfer_cortex_noncortex_labels.output_file',
                VolShapeFlow,
                'Thickness_per_freesurfer_cortex_label.labeled_file')
            FSthicknesses.inputs.cortex_value = 2
            FSthicknesses.inputs.noncortex_value = 3
            FSthicknesses.inputs.labels = dkt.cerebrum_cortex_numbers
            FSthicknesses.inputs.names = dkt.cerebrum_cortex_names
            FSthicknesses.inputs.resize = True
            FSthicknesses.inputs.propagate = False
            FSthicknesses.inputs.output_dir = ''
            FSthicknesses.inputs.save_table = True
            FSthicknesses.inputs.output_table = \
                'thickinthehead_per_freesurfer_cortex_label.csv'
            # Save table:
            mbFlow.connect(VolShapeFlow,
            'Thickness_per_freesurfer_cortex_label.output_table',
            Sink, 'tables.@thicknesses_of_freesurfer_labels')
            # ----------------------------------------------------------------
            # Thicknesses of the ANTs cortical labels:
            # ----------------------------------------------------------------
            if use_ants:
                ANTsThicknesses = FSthicknesses.\
                    clone('Thickness_per_ants_cortex_label')
                VolShapeFlow.add_nodes([ANTsThicknesses])
                if my_graywhite:
                    ANTsThicknesses.inputs.segmented_file = my_graywhite
                else:
                    if overwrite_cerebrum_with_cerebellum:
                        mbFlow.connect(VolLabelFlow,
                            'Remove_cerebrum_cerebellum_overlap.output_file',
                            VolShapeFlow,
                            'Thickness_per_ants_cortex_label.'
                            'segmented_file')
                    else:
                        mbFlow.connect(VolLabelFlow,
                            'Combine_freesurfer_ants_cerebrum_graywhite.'
                            'output_file',
                            VolShapeFlow,
                            'Thickness_per_ants_cortex_label.'
                            'segmented_file')
                if overwrite_cerebrum_with_cerebellum:
                    mbFlow.connect(VolLabelFlow,
                      'Add_freesurfer_cerebellum_to_ants_cerebrum.output_file',
                      VolShapeFlow,
                      'Thickness_per_ants_cortex_label.labeled_file')
                else:
                    mbFlow.connect(VolLabelFlow,
                      'Combine_ants_cortex_noncortex_labels.output_file',
                      VolShapeFlow,
                      'Thickness_per_ants_cortex_label.labeled_file')
                ANTsThicknesses.inputs.labels = dkt.cerebrum_cortex_numbers
                ANTsThicknesses.inputs.names = dkt.cerebrum_cortex_names
                ANTsThicknesses.inputs.output_table = \
                    'thickinthehead_per_ants_cortex_label.csv'
                # Save table:
                mbFlow.connect(VolShapeFlow,
                   'Thickness_per_ants_cortex_label.output_table',
                   Sink, 'tables.@thicknesses_of_ants_filled_cortex_labels')


# ============================================================================
# ----------------------------------------------------------------------------
#
#   Run workflows
#
# ----------------------------------------------------------------------------
# ============================================================================
if __name__ == '__main__':

    from time import time
    time0 = time()

    # ------------------------------------------------------------------------
    # Workflow configuration: provenance tracking, content hashing, etc.:
    # ------------------------------------------------------------------------
    # config.enable_provenance()
    mbFlow.config['execution']['hash_method'] = 'content'
    # mbFlow.config['execution']['use_relative_paths'] = True

    # ------------------------------------------------------------------------
    # Generate a visual graph:
    # ------------------------------------------------------------------------
    graph_vis = args.graph
    if graph_vis:
        if graph_vis == 'exec':
            mbFlow.write_graph(graph2use=graph_vis, simple_form=False)
        else:
            if graph_vis == 'hier':
                graph_vis = 'hierarchical'
            mbFlow.write_graph(graph2use=graph_vis)

    # ------------------------------------------------------------------------
    # Debug: http://nipy.org/nipype/users/config_file.html#debug-configuration
    # ------------------------------------------------------------------------
    debug = False
    if debug:
        config.set('logging', 'workflow_level', 'DEBUG')
        logging.update_logging(config)
        mbFlow.config['execution']['stop_on_first_rerun'] = True
        cpus = 1
    else:
        cpus = args.cpus

    # ------------------------------------------------------------------------
    # Run with or without a plugin:
    # ------------------------------------------------------------------------
    if args.plugin:
        if args.plugin_args:
            mbFlow.run(plugin=args.plugin, plugin_args=eval(args.plugin_args))
        else:
            mbFlow.run(plugin=args.plugin)
    elif cpus > 1:
        mbFlow.run(plugin='MultiProc', plugin_args={'n_procs': cpus})
    else:
        mbFlow.run()

    print('Mindboggle run for {0} complete! ({1:0.2f} seconds)'.
          format(DATA, time() - time0))
